# Chat Assistant Project

## Overview
This project implements a Chat Assistant using FastAPI for the backend and JavaScript for the frontend. The assistant interacts with various Language Learning Models (LLMs) to provide responses to user queries.

## Requirements
- FastAPI
- LiteLLM
- JavaScript

## Deployment
The Chat Assistant is deployed on Render.com. You can access it [here](https://your-chat-assistant-url).

## Extensions
- Text file uploads to add to the prompt context.
- Image file uploads for multimodal LLMs.
- Side-by-side LLM response comparison.

## Getting Started
1. Clone the repository.
2. Install the required dependencies.
3. Run the FastAPI server.
4. Open the frontend in your browser.